# 자율 프로젝트 고민 사항 모음

### 1. 회원 가입 시 소프트 딜리트 유저 확인하는 로직 추가 

- 탈퇴 유저의 LoginID, PhoneNumber, DeviceId는 다시 쓸 수 있어야 됨
- 구현 방법
  - **유니크 인덱스 수정 (필터링된 인덱스 또는 부분 인덱스 사용)**
    - 소프트 딜리트된 레코드에 대해 필드의 유니크 인덱스를 비활성화하고, 활성 사용자에 대해서만 유니크 제약 조건을 유지하는 방법

  - **로그인 ID 변경 (타임스탬프, UUID, 접두사 사용)**
    - 소프트 딜리트 처리 시, LoginId에 타임스탬프, UUID, 또는 특정 접두사를 추가하여 고유성을 깨뜨리는방법. 예를 들어, 사용자가 탈퇴하면 LoginId를 "deleted_" + 원래 LoginId로 변경할 수 있습니다
- 채택
  - **유니크 인덱스 수정 (필터링된 인덱스 또는 부분 인덱스 사용)**

### 2. Access-Token, Refresh-Token Secret-Key 분리

- 일반적으로?는 하나의 Secret-key를 이용해 Access-Token, Refresh-Token을 생성하는 거 같음. 그러나 하나의 Secret-Key를 사용하면 refresh_token을 헤더에 access_token 대신 담아서 보내도 인증이 허가가 됨

- 각 토큰의 용도에 맞는 역할만 수행하기 위해 토큰 별로 Secret-Key를 달리하여 토큰을 생성하기로 함

### 3. permitall() URL에 따른 헤더에 Access 토큰을 담아서 보냈을 때 예외가 발생시키지 않도록 하기 위한 처리 

- `JwtAuthenticationFilter`는 코드를 보면 알겠지만, `JwtAuthenticationFilter`는 모든 요청에 헤더의 `Authentication` key에서 Bearer 라는 문자열이 value의 접두사로 포함되어 있으면 Bearer 뒤에 작성된 Accesstoken을 추출하고 유효성을 검사함.
  - 인증이 필요한 URL (`permitall` X) 의 경우
    - `Authentication 헤더`에 토큰을 담지 않는 요청의 경우 
      -> `Security의 필터체인`을 로직을 모두 거친 다음, 인증 실패로 인해 `AuthenticationEntryPoint` 로 에러 핸들링 됨
    - `Authentication 헤더`에 토큰을 담았으나 토큰이 잘못된 경우
      -> 해당 메서드에서 `try-catch`로 에러 처리함.
      -> 토큰을 검증하는 로직 자체에서 에러가 발생하므로 `AuthenticationEntryPoint`로 에러 핸들링 안됨.
  - 인증이 필요없는 URL (`pertmiall` O)의 경우
    - `Authentication 헤더`에 토큰을 담지 않는 요청의 경우
      ->  `Security의 필터체인`을 로직을 모두 거친 다음, 인증은 실패하나 `pertmitall` 이므로 정상 동작 함
    - `Authentication 헤더`에 토큰을 담은 경우
      -> `JwtAuthenticationFilter`에서 토큰을 검사하는 로직을 수항하지 않고 바로 다음 필터로 넘기기

  - **쉽게 생각하면 `JwtAuthenticationFilter`는 인증이 필요한 요청에 대해서만 로직을 활성화 한다고 생각하면 됨**
    - permitall 요청에 대해서는 로직을 실행하지 않고 다음 필터로 넘기기고, 인증이 필요한 요청에 대해서만 토큰이 null이거나 유효하지 않을 때에 대한 에러처리를 하면 됨.
    - 위 로직에서 Access토큰이 null 일때 별도로 에러 처리하는 로직을 만들면 `AuthenticationEntryPoint`는 필요가 없어 보이긴 함 (이거는 하기 나름일듯)

### 4. JwtAuthenticationFilter 가 필터 체인에 중복 등록되는 에러

- 참고 : [바로가기](https://shanepark.tistory.com/497)

- **원인**

  - 의존성 주입을 받기 위해 `JwtAuthenticationFilter`를 `@Bean`으로 등록한 뒤, `Security Config`

    에서 명시적으로 해당 필터를 필터체인에 등록 한 것이 원인.

    - Servlet, Filter, Listener 같은 구현체가 스프링 빈(Bean)으로 등록되면, Spring Boot는 이 구현체들이 서블릿 컨테이너에 자동으로 등록되도록 설정 함.
    - **즉, Filter의 구현체를 Spring Bean으로만 등록해도 Spring Boot가 필터 체인에 해당 필터를 자동으로 등록하는 것을 의미 함(대신 원하는 순서에 필터를 추가하기가 까다로움)**

  - 결국 똑같은 필터가 자동으로, 수동으로 총 2번 등록 됨.

- **해결**

  - 필터가 자동으로 FilterChain에 등록되지 않도록 `@Component` 어노테이션을 제거

  - `Security Config`에서 해당 `Filter`를 생성자를 통해 생성하고 필터 체인에 명시적으로 등록해서 해결함

    ```java
    public class SecurityConfig {
         			
                        ...중략
        @Bean
        public SecurityFilterChain filterChain(HttpSecurity httpSecurity, AuthenticationManager authenticationManager) throws Exception {
            LoginIdAuthenticationFilter loginIdAuthenticationFilter = new LoginIdAuthenticationFilter(authenticationManager, customAuthenticationSuccessHandler, objectMapper);
            JwtAuthenticationFilter jwtAuthenticationFilter = new JwtAuthenticationFilter(jwtUtil, objectMapper);
            return httpSecurity               
                	... 중략
                    .addFilterBefore(jwtAuthenticationFilter, UsernamePasswordAuthenticationFilter.class)
                    .build();
        }
    
    //@Component 빼기
    public class JwtAuthenticationFilter extends OncePerRequestFilter {
    				...중략
    }
    ```
  
    

### 5. userRepository의 save메서드에서 duplicate key 에러가 발생했는데, 응답이 CustomAuthenticationEntryPoint의 코드로 처리 되는 버그

- **상황**

  - `/api/users` 요청에 대해, `UserService` 클래스에서 `Duplicate Key` 에러가 발생했으나 해당 에러에 대해 명시적으로 핸들링되고 있지 않았음. 그런데 클라이언트에게는 `Security FilterChain`의 `AuthenticationException`의 핸들링을 담당하는 `CustomAuthenticationEntryPoint`에 작성된 응답이 반환됨

- **해결 과정**

  - `JwtAuthenticiationFilter`에 문제가 있을걸로 예상하고. Sout과 Intellij의 디버거를 사용해 디버깅을 해보니 3가지 문제점을 발견함

    1. `request`가 `Controller` 매핑 전 `FilterChain`을 통과하는 과정에서 `JwtAuthenticiationFilter`가 2번 호출돼서 `filterhain.doFilter()`전 작성된 로직이 2번 실행되는 현상을 발견
       -> 위의 4번 에러 및 고민을 통해 해결

    2. `JwtAuthenticiationFilter`에서  `filterhain.doFilter()` 이후에  작성된 부분이 응답이 반환되는 과정에서 실행(후처리) 되는 건지를 몰랐음 -> `filterhain.doFilter()` 이후에 return을 추가해서 후처리 부분을 없애서 해결

       - ```java
         @RequiredArgsConstructor
         public class JwtAuthenticationFilter extends OncePerRequestFilter {
         			
         			... 중략
                 if (skip) {
                     filterChain.doFilter(request, response);
                     return; // return 추가
                 }
               
                 	... 중략
             }
         ```

    3. **(중요) 위 2가지를 해결한 상태로 디버깅을 했는데, `/api/users`요청에 대해 Service로직에서 에러가 발생하고 `/api/error` URL로 request가 다시 실행되는 과정을 발견함** 

       -  `UserService`에서 발생한 `Duplicate Key` 에러는 명시적인 핸들링이 되지 않는 상황이었고, Spring에 기본 내장된 `BasicErrorController` 가 에러를 처리하게 됨. 
       - **`BasicErrorController`의 에러 처리는 예외가 발생하면 기본적으로 `/error`  URL로 리다이렉트 하는 것임.** 그래서 `/api/error` URL로 request가 다시 한 번 실행되는 것이었음
       - 리다이렉트 된 `/api/error` request가 `filterChain`을 통과 하면서  `AuthenticationException`가 발생. (인증되지 않은 클라이언트가 인증된 URL로 접근을 시도해서 발생)
       - `filterChain`에서 발생한 `AuthenticationException`에 대해서는 `CustomAuthenticationEntryPoint`가 핸들링 하기 때문에 `CustomAuthenticationEntryPoint`에 작성된 `response`가 반환된 것임
       - **결국, `SecurityConfig`에 `/error` URL에 대해 `permitall()`을 적용시켜 `/error `리다이렉션 요청이 진행하는 과정에서 `AuthenticationException`이 발생하지 않도록 조치하여 정상적인 응답이 반환되도록 해결함**

- **핵심 요약**

  - `AuthenticationEntryPoint`에 작성된 응답이 반환되었던 이유

    - ```java
      // 첫 번째 /api/users Request 처리 과정
      1. /api/users Request -> WAS -> 필터 -> 서블릿(디스패처 서블릿) -> 인터셉터 -> 컨트롤러 -> 서비스 로직(예외 발생) -> 컨트롤러 -> 명시적인 핸들링 없음 -> BasicErrorController(스프링 MVC의 기본 예외 처리) -> /error로 리다이렉션 -> 서블릿(디스패처 서블릿) -> 인터셉터 -> 필터 -> WAS(/error 요청 생성)
      
      // 두 번째 /api/error requset 처리 과정
      // properties에 작성된 prefix설정 때문에 /api 접두사가 붙음
      2. WAS(/api/error Request 생성) -> 필터
      -> /api/error은 인증이 필요한 URL로 AuthenticationException 발생
      -> AuthenticationEntryPoint 응답 생성
      -> WAS
      -> Client 응답 반환
          
      ▣ 참고
      FilterChain에서 발생한 예외는 보안 관련 예외이기 때문에, 시스템의 무결성과 사용자의 보안을 지키기 위해 빠른 응답이 필요함. 이를 위해 FilterChain을 역순으로 거슬러 올라가지 않고 WAS를 통해 바로 클라이언트에게 응답을 전송하는 방식을 사용함.
      ```
  
  - **해결 방법**
    - `/error` URL에 대해 `permitall()`을 적용시켜 리다이렉션으로 인한 `/error`요청에 대해`AuthenticationException`이 발생하지 않도록 함

### 6. GPU 서버의 FASTAPI에서 rabbbitMQ로 메시지 발송 시, rabbitMQ 채널이 닫혀있다는 오류가 발생

**(자율 프로젝트 레빗엠큐 관련 에러 TIL 참고)**

- **상황**
  - GPU 서버의 FASTAPI에서 rabbbitMQ로 메시지 발송 시, rabbitMQ 채널이 닫혀있다는 오류가 발생
  - 에러 메시지 분석 결과, rabbitMQ와의 연결이 끊어진 게 아니라 채널이 닫혀있는데 메시지를 발송하려고 해서 발송하지 못한다는 에러였음

- **문제 해결**
  - 기존 코드 분석 결과, 메시지 발송 마다 채널을 재생성하고 큐를 지정하고 있었음
    - 채널을 재생성하는 것이 원인이지 않을까 싶어 해당 코드를 사용하지 않고 전역에 설정된 채널을 이용하여 publish 작업만 하도록 코드를 수정하였음 -> 여전히 똑같은 오류가 발생함
    - 채널이 닫혀있으면 채널을 재생성하고 연결하도록 코드를 수정 -> 해결되지 않음

  - **에러 메시지 중 `Exception in thread Thread-1625 (_handle_eio_message):` 확인**
    - 해당 메시지는 1625번 쓰레드에서 발생하였다는 내용임 -> 쓰레드가 1625개나 된다는게 이상했음
    - 각 쓰레드가 동일한 채널을 연결하고 있는거라면 채널 입장에서는 너무 많은 연결에 대응하기 위해 채널을 닫는 것이 맞음

    - 웹소켓 메시지 수신 이벤트가 발생할 때 마다 쓰레드를 생성하여 작업하는 것이 default라서 쓰레드가 계속해서 생성되고 있었음

  - **쓰레드를 계속해서 생성하지 않고 10개의 쓰레드 내에서 재사용하도록 코드를 수정하여 에러를 해결**

- **정리**
  - **GPU 서버에서 웹소켓 메시지 수신 이벤트가 발생할 때 마다 RabbitMQ와 Connection을 담당하는 쓰레드를 생성하였고, RabbitMq 입장에서 하나의 Connection에 너무 많은 쓰레드가 할당되니까 해당 채널을 닫아버리는 거였음. 명시적으로 쓰레드를 10개 내에서 재사용하도록 코드를 수정하여 에러를 해결 함**




### 7. GPU 서버에서 이미지 처리(객체감지 및 속도 분석)가 원할하게 이루어 지지 않았던 문제

- **상황**
  - CCTV 영상 내 과속 차량을 분석하기 위해, 휴대폰 카메라로 찍은 영상 이미지를 바이너리 데이터(blob 데이터 타입)로 변환한 뒤 WebSocket을 통해 GPU 서버에 10 FPS(초당 10장) 씩 전송했음. GPU 서버에서는 바이너리 데이터를 다시 이미지로 변환하여 이미지 처리 로직을 수행하고 있던 상황
  - 하지만, FastAPI 서버를 실행하면 이미지 처리를 위해 사용하던 Yolo v9 모델의 로드가 너무 오래걸렸음. 또한, 이미지 처리 직후에 로그를 출력하도록 했는데, 당시 로그 출력 속도가 불규칙했음. 일정한 주기로 로그 출력이 와장창 찍혔다가(정상 동작) 천천히 찍혔다가(비정상적 동작)를 반복하는 느낌이었음. 
  - 또한, 이미지 처리 로직 마지막에는 GPU서버에서 RabiitMq로 데이터를 publish하는 코드가 있었는데, 로그 출력이 와장창 찍힐 때는 publish가 정상적으로 실행되었고, 로그 출력이 천천히 찍힐 때는 publish코드가 아예 실행되지 않았음. 이를 통해 로그 출력이 와장창 찍힐 때는 정상적으로 이미지 처리가 이루어지고, 로그 출력이 천천히 찍힐 때는 원인 모를 노이즈가 생기며 비정상적인 동작을 하고 있다는 것을 의심하게 됨.
- **문제 해결 과정**
  - GPU 서버에서는 0.1초당 1장의 이미지를 수신했고, 이미지 처리 로직의 수행 시간은 1장당 0.02초 정도로 확인했음. 이에 따라, 0.08초의 시간이 여유가 있으므로, 처리할 이미지 량과 이미지 처리 속도 사이에서는 문제가 없을 것으로 유추함.
  - (6번 문제와 비슷한 상황) 가끔식 출력되는 에러 로그 중, 쓰레드가 1000번을 넘어가는 것을 발견하게 되었음. 이에 이미지를 처리하는 로직에 사용하는 쓰레드가 이미지 1장 당 새로운 쓰레드가 할당되면서, 이미지를 처리하는 작업이 비동기로 수행되는 것이 문제가 될 수 있음을 추측함
  - 해결을 위해, 이미지를 저장하는 Queue를 만들고 1개의 쓰레드만을 명시적으로 Queue에 할당함. 이미지 처리 로직은 Queue에 연결된 1개의 쓰레드로만 수행되었고, 결과적으로 이미지를 Queue에서 꺼내어 작업을 수행하는 과정이 동기적으로 처리되면서 문제가 해결됨. (이미지를 수신해서 Queue에 저장하는 로직과 Queue에서 이미지를 꺼내는(이미지를 처리하는) 로직은 독립적으로 동작함)
- **정리**
  - **이미지를 처리하는 로직에서 이미지 1장당 새로운 쓰레드가 1개 씩 생성되었고, 많은 쓰레드 수와 비동기적인 작업이 동반되면서 발생한 부하가 비정상 동작을 초래한 것으로 예상함. 이에 Queue를 만들어 명시적으로 쓰레드를 1개만 할당하고 동기적으로 로직을 수행하도록 수정하여 문제를 해결함.**

### 8. Jenkins에 apk파일을 빌드하는 과정을 추가했더니, EC2 메모리 초과로 서버가 고장나고, ssh 접속이 안되는 상황 발생.

- **상황 정리**

  - 최종 발표 이틀 전 주말에 jenkins를 통해 apk파일을 자동 빌드하고, nginx를 통해 해당 파일을 클라이언트에게 제공하도록 설정을 해 놓았음.

  - 당시 EC2 인스턴스에 실행되고 있는 컨테이너는 ELK(3개), spring, cctv, admin, RabiitMq, postgres, redis 9개로  사용가능한 메모리는 2GB 정도 였음

  - jenkins의 파이프라인이 4개 였기에 파이프라인이 동시에 실행되면 메모리 초과로 EC2 인스턴스가 다운 되지 않을까 고민은 해었음.

  - 하지만, 2GB의 메모리면 충분하다고 생각했고 혹여나 메모리가 초과 되더라도 jenkins 컨테이너만 종료되지 않을 까 생각하여 크게 문제가 안될거라 생각했음.

  - 결국, 새벽에 팀원이 gitlab에 소스코드를 push하여 jenkins 파이프라인이 실행되고, apk파일을 만드는 과정에서 메모리 초과가 발생하여 jenkins 컨테이너가 종료되었음. 
  - 초기에는 jenkins 컨테이너만 종료되고 ssh 접속은 가능했었으나, 시연 연습 직전에 ssh 접속이 안되는 현상이 발생.
    `ssh: connect to host k10e202.p.ssafy.io port 22: Connection timed out`
  - **주말이지만 급하게 사무국에 연락하여 EC2 인스턴스 재부팅을 요청하였고, 인스턴스 재부팅 후 ssh 접속이 가능하여 apk파일 빌드관련 파이프라인을 지우고 문제를 해결했음.**



### 9. EC2의 디스크 용량 100%사용으로 Spring, Postgre, Kibana 등 컨테이너가 실행 중인데 정상 동작을 하지 않는 에러 

- 상황정리
  - 프로젝트가 끝난 후 오랜만에 애플리케이션에 접속해서 로그인을 하려고 했는데, 에러 응답이 리턴됐음.
  - Kibana를 접속해서 로그를 확인해 보려고 하니, Kibana도 에러가 뜨면서 접속이 안됨.
  - EC2의 도커 컨테이너도 정상적으로 다 실행되고 있었고, DB에 저장된 데이터들도 모두 정확했음.
  - 잠깐 뒤에 DB GUI 툴에서 Postgres의 서버가 연결에 실패 하게 되었고 `"FATAL: could not write init file"` 에러가 발생함을 확인.
  - 해당 에러가 디스크 공간이 부족해서 발생할 수 있음을 인지하고, EC2의 디스크 사용 정보를 확인했더니 99.8% 가 사용중임을 확인 함
- **문제 해결 과정**
  - EC2 인스턴스 내에 추가적인 파일을 설치하거나 업로드 한 게 아니었기 때문에 어디서 용량을 많이 잡아먹고 있는지 유추하던 중, Spring Container의 log파일의 용량이 129GB인 것을 확인 함.
  - 해당 로그 파일을 지우니까 Kibana, Spring, postgres 등 모든 컨테이너들이 정상 동작 함.
  - Kibana에 접속해서 로그를 분석해 보니, 프로젝트 기간이 끝난 후 임의의 사용자가 며칠 동안 GPU 서버를 가동하여 엄청난 수의 request를 Spring 서버로 보내었고, 이로 인해 로그가 Spring Container의 로그 파일에 누적되면서 용량이 129 GB까지 도달하게 되었던 것임.
